# Travelpayouts API Data Extractor

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)  <!-- Замените LICENSE на ссылку на ваш файл лицензии, если есть -->

## Описание

Этот проект автоматизирует извлечение данных из Travelpayouts API и сохранение их в структурированные CSV-файлы. Он предназначен для сбора и организации данных о выплатах, действиях и деталях действий для последующего анализа и отчетности. Процесс извлечения, преобразования и загрузки (ETL) данных организован в виде пайплайна, обеспечивающего последовательную и автоматизированную обработку.

## Цель

Автоматизировать процесс получения данных из Travelpayouts API для создания структурированной базы данных, пригодной для аналитики и отчетности. Реализовать инкрементальное обновление данных, чтобы избежать повторной обработки уже полученной информации.

## Требования

*   Python 3.x
*   Библиотеки:
    *   `requests`
    *   `pandas`
    *   `python-dotenv`
    *   `argparse`

## Установка

1.  Клонируйте репозиторий:

    ```bash
    git clone <your_repository_url>
    ```

2.  Создайте виртуальное окружение (рекомендуется):

    ```bash
    python3 -m venv venv
    source venv/bin/activate   # Linux/macOS
    venv\Scripts\activate.bat  # Windows
    ```

3.  Установите зависимости:

    ```bash
    pip install -r requirements.txt
    ```

4.  Создайте файл `.env` в корне проекта и добавьте API-токен Travelpayouts:

    ```
    TRAVELPAYOUTS_API_TOKEN=YOUR_API_TOKEN
    ```

    Замените `YOUR_API_TOKEN` на ваш реальный API-токен. Не коммитьте файл `.env` в репозиторий!

## Структура каталогов

<!-- В этом разделе опишите структуру каталогов проекта -->

## Использование

1.  Убедитесь, что у вас правильно настроены переменные окружения в файле `.env`.

2.  Запустите ETL pipeline с помощью скрипта `etl_pipeline.py`:

    ```bash
    python src/etl/pipeline/etl_pipeline.py
    ```

    Этот скрипт автоматически выполнит все необходимые шаги: извлечет данные о выплатах, действиях и деталях, сохранит их в соответствующие CSV-файлы и отметит обработанные периоды.

    *   Для первоначальной загрузки всех имеющихся данных, запустите скрипт без аргументов.
    *   Для инкрементального обновления данных (например, раз в месяц), просто запустите скрипт снова. Он автоматически определит, какие периоды еще не были обработаны, и извлечет только новые данные.

## Формат и именование файлов

Все данные сохраняются в формате CSV в папку `data/tpo_api_data/` и ее подпапки. Имена файлов соответствуют следующему формату:

1.  **Выплаты (Payments):**
    *   `data/tpo_api_data/payments/tpo_payments_YYYYMM_EXTRACTED.csv`
    *   Пример: `data/tpo_api_data/payments/tpo_payments_202401_EXTRACTED.csv` (Выплаты за январь 2024)

2.  **Действия по каждой выплате (Payment Actions):**
    *   `data/tpo_api_data/payment_actions/tpo_payment_actions_YYYYMM_EXTRACTED.csv`
    *   Пример: `data/tpo_api_data/payment_actions/tpo_payment_actions_202401_EXTRACTED.csv` (Действия по выплатам за январь 2024)

3.  **Детали по каждому действию (Action Details):**
    *   `data/tpo_api_data/action_details/tpo_action_details_YYYYMM_EXTRACTED.csv`
    *   Пример: `data/tpo_api_data/action_details/tpo_action_details_202401_EXTRACTED.csv` (Детали по действиям за январь 2024)

    *   `YYYYMM` - год и месяц, за который произведена выплата (извлекается из колонки `comment`).
    *   `EXTRACTED` - указывает, что это данные, непосредственно полученные из API.

## Описание скриптов

*   `src/etl/extract/extract_travelpayouts_payments.py`: Скрипт для извлечения данных о выплатах (начиная с января 2018).
*   `src/etl/extract/extract_travelpayouts_payment_actions.py`: Скрипт для извлечения действий по каждой выплате.
*   `src/etl/extract/extract_travelpayouts_action_details.py`: Скрипт для извлечения детализации по каждому действию.
*   `src/etl/pipeline/etl_pipeline.py`: Основной скрипт для запуска ETL pipeline.

## Инкрементальная обработка

Этот pipeline поддерживает инкрементальную обработку данных. При каждом запуске скрипт проверяет, какие периоды (месяц и год) уже были обработаны, и извлекает только новые данные. Информация об обработанных периодах хранится в файле `data/tpo_api_data/processed_dates.csv`.

## Дополнительная информация

*   **Обработка ошибок:** Скрипты содержат детальную обработку ошибок и логирование, что позволяет легко отслеживать процесс выполнения и выявлять проблемы. Особое внимание уделено обработке ошибок 404 (действие не найдено) от API.
*   **Изменения API:** Структура API Travelpayouts может меняться. Скрипты могут потребовать адаптации при изменениях API.
*   **Производительность:** Для больших объемов данных может потребоваться оптимизация производительности (например, использование многопоточности или асинхронных запросов).
*   **Ограничение по дате:** Данные из Travelpayouts API доступны только с января 2018 года. Попытки извлечения данных за более ранние периоды приведут к ошибкам.

## Лицензия

Этот проект лицензирован по лицензии MIT. Подробности см. в файле [LICENSE](LICENSE).

## Контакты

[Your Name](your.email@example.com) <!-- Замените на свои контакты -->